# Sweep values for "Large-Scale Methods for Distributionally
# Robust Optimization", Levy et al 2020.

# To view original defaults, see
# https://github.com/daniellevy/fast-dro/tree/main/hyperparameters

program: scripts/train.py
name: "abroca-fastdro-chisquare-constraint-sweep-cls"
description: "hyperparameter sweep for fast DRO with chi-square geometry (constraint version)."
method: random
metric:
  name: val_loss
  goal: minimize

parameters:
  model_type:
    values: [ "fastdro", ]
  # training parameters
  steps: # number of training steps
    values: [ 30000, ]
  batch_size:
    values: [ 32, 64, 128, 256, 512 ]
  # uncertainty set parameters
  geometry:
    values: [ "chi-square", ]
  size:
    values: [ 0.01, 0.05, 0.1, 0.4, 1.0 ]
  reg:
    values: [ 0.0 ]  # do not use chi-square penalty term in loss; using constraint instead.
  max_iter:
    values: [ 1000, ]
  # optimization parameters
  optimizer:
    values: [ "sgd", ]
  criterion_name:
    values: [ "fastdro", ]
  momentum:
    values: [ 0.99, 0.9, 0.5, 0.1, 0.0 ]
  weight_decay:
    values: [ 1e-1, 1e-2, 1e-3, 1e-4, 0.0 ]
  learning_rate:
    values: [ 0.1, 0.01, 0.001, 0.0001, 0.00001 ]
